{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jMpL5iTPyYG"
      },
      "outputs": [],
      "source": [
        "%pip install transformers\n",
        "%pip install scikit-learn\n",
        "%pip install modal\n",
        "%pip install datasets\n",
        "%pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qF_UGEOpPrDb"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import modal\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nGVnKenzjvh",
        "outputId": "447b32c1-b480-4fab-b2c2-1caf5f749400"
      },
      "outputs": [],
      "source": [
        "# Define the mapping from emotion names to numbers\n",
        "emotion_mapping = {\n",
        "    'admiration': 1, 'amusement': 2, 'anger': 3, 'annoyance': 4,\n",
        "    'approval': 5, 'caring': 6, 'confusion': 7, 'curiosity': 8,\n",
        "    'desire': 9, 'disappointment': 10, 'disapproval': 11, 'disgust': 12,\n",
        "    'embarrassment': 13, 'excitement': 14, 'fear': 15, 'gratitude': 16,\n",
        "    'grief': 17, 'joy': 18, 'love': 19, 'nervousness': 20, 'optimism': 21,\n",
        "    'pride': 22, 'realization': 23, 'relief': 24, 'remorse': 25, 'sadness': 26,\n",
        "    'surprise': 27, 'neutral': 28\n",
        "}\n",
        "\n",
        "def process_csv(file_path):\n",
        "    \"\"\"Processes a single CSV file.\"\"\"\n",
        "    df = pd.read_csv(file_path, delimiter=',')\n",
        "\n",
        "    # Find emotion numbers (same as your existing code)\n",
        "    emotion_numbers = []\n",
        "    for index, row in df.iterrows():\n",
        "        emotion_number = 0\n",
        "        for emotion, number in emotion_mapping.items():\n",
        "            if row['emotion'] == emotion:\n",
        "                emotion_number = number\n",
        "                break\n",
        "        emotion_numbers.append(emotion_number)\n",
        "\n",
        "    # Add emotion numbers as a new column\n",
        "    df['emotion'] = emotion_numbers\n",
        "\n",
        "    # Select relevant columns and ensure data types\n",
        "    new_df = df[['text', 'emotion']]\n",
        "    new_df['text'] = new_df['text'].astype(str)\n",
        "    new_df['emotion'] = new_df['emotion'].astype(int)\n",
        "\n",
        "    return new_df\n",
        "\n",
        "initial_labeled_data = process_csv('active_learning_emotions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 text  emotion\n",
            "0   Dear user, we've detected unauthorized access ...       15\n",
            "1   We've noticed a suspicious login attempt from ...       15\n",
            "2   Our systems have detected unusual activity on ...       15\n",
            "3   Be advised that we've identified an attempt to...       15\n",
            "4   Our security system has flagged your account f...       15\n",
            "5   Discover the secrets of your account with hidd...        8\n",
            "6   Ever wondered how secure your data really is? ...        8\n",
            "7   We've added some exciting new features to your...        8\n",
            "8   We've made a change to your account. Can you s...        8\n",
            "9   We have a surprise waiting in your account. So...        8\n",
            "10  This is your chance! An exclusive offer just f...       14\n",
            "11  Congratulations! Your account has been selecte...       14\n",
            "12  You've earned it! A special reward awaits you ...       14\n",
            "13  Get ready for an exciting opportunity! You're ...       14\n",
            "14  You're almost there! Confirm your details now ...       14\n",
            "15  We noticed a discrepancy in your account infor...        7\n",
            "16  There's been some unusual activity on your acc...        7\n",
            "17  You've received a message in your account that...        7\n",
            "18  Our system has sent out some conflicting alert...        7\n",
            "19  It appears there have been changes to your acc...        7\n",
            "20  As part of our commitment to your security, we...        6\n",
            "21  Your experience is important to us. Help us im...        6\n",
            "22  Noticed something off with your account? We're...        6\n",
            "23  Your privacy and security are our top priority...        6\n",
            "24  We're grateful to have you with us. As a token...        6\n",
            "25  This is your last warning. Your account will b...       15\n",
            "26  Your account security is compromised. Immediat...       15\n",
            "27  We've detected potential fraud on your account...       15\n",
            "28  ALERT: Your account is at high risk of hacking...       15\n",
            "29  We've noticed unusual sign-in activity. Verify...       15\n",
            "30  Something big is coming to your account. Can y...        8\n",
            "31  Your account usage reveals interesting secrets...        8\n",
            "32  We've hidden a surprise in your account just f...        8\n",
            "33  We've quietly rolled out a new feature in your...        8\n",
            "34  There's a hidden message in your account waiti...        8\n",
            "35  Your exclusive access to our new feature is ex...       14\n",
            "36  This is your last chance to grab our special d...       14\n",
            "37  FLASH SALE: A limited-time offer just for you....       14\n",
            "38  You're invited to an exclusive event. Spaces a...       14\n",
            "39  Special benefits have been added to your accou...       14\n",
            "40  We've detected unusual sign-in activity on you...        7\n",
            "41  There seems to be an error with your account v...        7\n",
            "42  We've received conflicting information regardi...        7\n",
            "43  Your subscription status shows conflicting dat...        7\n",
            "44  A request to change your password was made, bu...        7\n",
            "45  To better serve you, we're inviting you to upd...        6\n",
            "46  Just a friendly reminder that an update is ava...        6\n",
            "47  As a token of our appreciation for your contin...        6\n",
            "48  Your opinion is invaluable to us. Share your t...        6\n",
            "49  We've made some updates to your account. Click...        6\n"
          ]
        }
      ],
      "source": [
        "initial_labeled_data.shape\n",
        "print(initial_labeled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['message_id', 'text', 'label', 'label_text', 'subject', 'message', 'date'],\n",
            "    num_rows: 31716\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "enron_dataset = load_dataset('SetFit/enron_spam')\n",
        "\n",
        "print(enron_dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained RoBERTa\n",
        "model_name = \"SamLowe/roberta-base-go_emotions\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "# model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YGJs43LlAyby"
      },
      "outputs": [],
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)  # Use your model_name\n",
        "\n",
        "# def tokenize_function(examples):\n",
        "#     return tokenizer(examples, padding='max_length', truncation=True)\n",
        "\n",
        "# tokenized_dataset = initial_labeled_data['text'].map(tokenize_function)\n",
        "\n",
        "# Updated logic for accessing tokenized data (assuming PyTorch)\n",
        "# X_train = [encoding['input_ids'] for encoding in tokenized_dataset]\n",
        "# y_train = [encoding['input_ids'] for encoding in initial_labeled_data['emotion'].map(tokenize_function)]\n",
        "\n",
        "class SentimentData(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = self.data.emotion\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = initial_labeled_data.reset_index(drop=True)\n",
        "training_set = SentimentData(train_data, tokenizer, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UVuEPXIhCaRz"
      },
      "outputs": [],
      "source": [
        "def get_new_labels_from_human(unlabeled_examples):\n",
        "    new_labels = []\n",
        "\n",
        "    for example in unlabeled_examples:\n",
        "        print(\"Example:\", example)\n",
        "        # Example - assuming your labels are simple:  'positive', 'negative', 'neutral'\n",
        "        label_choice = input(\"Choose one: 'positive', 'negative', 'neutral': \")\n",
        "        while label_choice not in ['positive', 'negative', 'neutral']:\n",
        "            print(\"Invalid input. Please enter one of the valid choices.\")\n",
        "            label_choice = input(\"Choose one: 'positive', 'negative', 'neutral': \")\n",
        "        new_labels.append(label_choice)\n",
        "\n",
        "    return new_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ZGfARgbzPuwd",
        "outputId": "8fc4dc13-9431-4cf5-c080-e2e46214ea16"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, y_train)  \u001b[38;5;66;03m# Replace loss_function with an appropriate loss\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/Tese/Thesis/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Tese/Thesis/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Tese/Thesis/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
            "File \u001b[0;32m~/Tese/Thesis/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Tese/Thesis/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Tese/Thesis/.venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:789\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 789\u001b[0m batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[1;32m    790\u001b[0m device \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m inputs_embeds\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# past_key_values_length\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# ... Assuming you have X_train and y_train prepared as tensors\n",
        "num_iterations = 10\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())  # Example optimizer\n",
        "train_dataloader = DataLoader(X_train, batch_size=16, shuffle=True)\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=batch[0], attention_mask=batch[1])\n",
        "        loss = loss_function(outputs, y_train)  # Replace loss_function with an appropriate loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Query strategy: Uncertainty Sampling\n",
        "    model.eval()  # Switch model to evaluation mode for uncertainty estimation\n",
        "    query_idx = modal.uncertainty_sampling(model, X_unlabeled)\n",
        "\n",
        "    # Get labels from a human annotator for the selected instances\n",
        "    new_labels = get_new_labels_from_human(X_unlabeled[query_idx])\n",
        "\n",
        "    # Update datasets (assuming new_labels is a list or array)\n",
        "    X_train = np.concatenate([X_train, X_unlabeled[query_idx]])\n",
        "    y_train = np.concatenate([y_train, new_labels])\n",
        "\n",
        "    # Remove queried instances from the unlabeled pool\n",
        "    X_unlabeled = np.delete(X_unlabeled, query_idx, axis=0)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
