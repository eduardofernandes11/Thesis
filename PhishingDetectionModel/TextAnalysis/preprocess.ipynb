{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rezett/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from transformers import BertTokenizer\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from email.header import decode_header\n",
    "from quopri import decodestring\n",
    "from html.parser import HTMLParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rezett/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/rezett/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stop words and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from quopri import decodestring\n",
    "from email.header import decode_header\n",
    "\n",
    "def clean_text(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    \n",
    "    # Step 1: Remove email headers like \"Content-Type\", \"Content-Transfer-Encoding\", boundaries, etc.\n",
    "    # This regex removes lines that start with boundary markers or headers.\n",
    "    text = re.sub(r'(--[-_a-zA-Z0-9]+|Content-[^:]+:[^\\n]+\\n)', '', text)\n",
    "    \n",
    "    # Step 2: Decode quoted-printable encoding artifacts\n",
    "    try:\n",
    "        # First, replace soft line breaks that look like =\\n and remove remaining = signs.\n",
    "        text = text.replace('=\\n', '')  # Soft line breaks in quoted-printable\n",
    "        \n",
    "        # Decode quoted-printable encoding using `decodestring` from quopri\n",
    "        text = decodestring(text).decode('utf-8', errors='ignore')  # Decode quoted-printable to UTF-8\n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding quoted-printable text: {e}\")\n",
    "        pass  # Handle the case where decoding fails\n",
    "    \n",
    "    # Step 3: Remove HTML tags if any remain\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Step 4: Normalize whitespaces and remove extra spaces or newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Step 5: Decode any additional email headers if present (like encoded subjects)\n",
    "    text = decode_headers(text)\n",
    "\n",
    "    # Step 6: Strip leading and trailing whitespaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Optional helper function to decode headers in case they are encoded\n",
    "def decode_headers(header_text):\n",
    "    if header_text:\n",
    "        # Decode headers like \"=?utf-8?Q?...?=\"\n",
    "        decoded_parts = decode_header(header_text)\n",
    "        decoded_string = ''\n",
    "        for part, encoding in decoded_parts:\n",
    "            if isinstance(part, bytes):\n",
    "                if encoding is None:\n",
    "                    decoded_string += part.decode('utf-8', errors='ignore')\n",
    "                else:\n",
    "                    decoded_string += part.decode(encoding, errors='ignore')\n",
    "            else:\n",
    "                decoded_string += part\n",
    "        return decoded_string\n",
    "    return header_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "\n",
    "    # Step 1: Remove quoted-printable encoding artifacts\n",
    "    text = text.replace('=\\n', '')  # Remove soft line breaks\n",
    "    text = text.replace('=', '')  # Remove remaining '=' characters\n",
    "\n",
    "    # Step 2: Remove MIME boundaries, content-type, and charset declarations\n",
    "    mime_pattern = r'(--[-_a-zA-Z0-9]+|Content-[^:]+:[^\\n]+\\n|charset=\"[^\"]+\"|MIME-Version:[^\\n]+\\n)'\n",
    "    text = re.sub(mime_pattern, '', text)\n",
    "\n",
    "    # Step 3: Remove base64-like encoded binary content\n",
    "    base64_pattern = r'[A-Za-z0-9+/]{40,}={0,2}'\n",
    "    text = re.sub(base64_pattern, '', text)\n",
    "\n",
    "    # Step 4: Use BeautifulSoup to remove HTML tags and decode entities\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "    # Step 5: Remove corrupted MIME artifacts or non-readable sequences\n",
    "    text = re.sub(r'\\.[A-Za-z0-9]{7,}', '', text)\n",
    "\n",
    "    # Step 6: Replace multiple spaces, newlines, or tabs with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Step 7: Strip leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11558/654631364.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, 'html.parser').get_text()\n",
      "/tmp/ipykernel_11558/654631364.py:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of email bodies: 2544\n",
      "Number of email bodies after removing duplicates: 2164\n",
      "0    You will not see this in a MIME-aware mail rea...\n",
      "1    This is a multi-part message in MIME format. c...\n",
      "2    You will not see this in a MIME-aware mail rea...\n",
      "3    Mail Quota: (98% Full) Attention: jose Your em...\n",
      "4    You will not see this in a MIME-aware mail rea...\n",
      "Name: message, dtype: object\n",
      "0    plot(fn,-1,1) could be helpful, hth, Ingmar On...\n",
      "1    CNN Alerts: bush Alert Name: bush Bush talks t...\n",
      "2    Hello sm1lies, This week we've got $34,050 in ...\n",
      "3    Hi, this evening I tried to add Festival and F...\n",
      "4    Napster Stock Quote Notification Stock informa...\n",
      "Name: message, dtype: object\n",
      "0    Important Security Message You will not see th...\n",
      "1    NEW PDF MESSAGE FROM AMERICAN EXPRESS ONLINE F...\n",
      "2    Confirm Your recent Transactions You will not ...\n",
      "3    =?UTF-8?B?WW91ciBFbWFpbCDinIkg?=jose@monkey.or...\n",
      "4    confirm This Transaction You will not see this...\n",
      "Name: message, dtype: object\n",
      "0    Re: [R] How to solve difficult equations? plot...\n",
      "1    CNN Alerts: bush CNN Alerts: bush Alert Name: ...\n",
      "2    This weeks' component news: $34,000+ in prizes...\n",
      "3    Speech-dispatcher, Festival and Flite Hi, this...\n",
      "4    Information for Napster Napster Stock Quote No...\n",
      "Name: message, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11558/4085025145.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['message'] = df_cleaned['subject'].fillna('') + ' ' + df_cleaned['message']\n"
     ]
    }
   ],
   "source": [
    "df_phishing = pd.read_csv('../jose_phishing.csv')\n",
    "df_ham = pd.read_csv('../trec_train.csv')\n",
    "\n",
    "# Apply the cleaning function to the extracted text\n",
    "df_phishing['message'] = df_phishing['body'].apply(clean_text)\n",
    "df_ham['message'] = df_ham['body'].apply(clean_text)\n",
    "\n",
    "# Check the number of original email bodies\n",
    "original_count = df_phishing.shape[0]\n",
    "\n",
    "# Remove duplicates based on the cleaned_body column\n",
    "df_cleaned = df_phishing.drop_duplicates(subset='message')\n",
    "\n",
    "# Check the number of email bodies after removing duplicates\n",
    "after_removal_count = df_cleaned.shape[0]\n",
    "\n",
    "# Output the results\n",
    "print(f\"Original number of email bodies: {original_count}\")\n",
    "print(f\"Number of email bodies after removing duplicates: {after_removal_count}\")\n",
    "\n",
    "# Select only the clean_text and label columns\n",
    "df_phishing = df_cleaned[['message', 'label']]\n",
    "df_ham = df_ham[['message', 'label']]\n",
    "\n",
    "# Save to a new CSV file\n",
    "df_phishing.to_csv('cleaned_phishing_emails.csv', index=False, errors='ignore')\n",
    "df_ham.to_csv('cleaned_ham_emails.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
